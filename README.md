# AI Red Team International Guideline

This document presents a comprehensive, process-centric international guideline for AI Red Teaming -- the structured adversarial testing of AI systems to discover vulnerabilities, failure modes, and potential harms across safety, security, and ethical dimensions.

These guidelines are being developed to ensure consistency with international standards and key guidelines, along with the latest risk/threat trends, red team technology research trends, and attack trends. To automate this process, we're using Claude Code's multi-agent co-work for HTML generation.

https://hollobit.github.io/RT-guideline-agent/

Orchestrator: Jonghong Jeon 
